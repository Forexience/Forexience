{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import calendar\n",
    "import dateutil.parser as parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime, timezone\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "import os, sys, glob\n",
    "import kaleido\n",
    "from PIL import Image\n",
    "from fpdf import FPDF\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.signal import argrelextrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(utc_time): \n",
    "    parsed_date = parser.parse(utc_time)\n",
    "    var_date=parsed_date.date()\n",
    "    var_time=parsed_date.time()\n",
    "    var_f_time=var_time.hour\n",
    "    var_julian_date=parsed_date.timetuple().tm_yday\n",
    "    var_weekday=parsed_date.weekday()\n",
    "    var_weekday_name=calendar.day_name[parsed_date.weekday()]\n",
    "    return var_date, var_time, var_f_time, var_julian_date, var_weekday, var_weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(data):\n",
    "    output=[]\n",
    "    for col in data.columns:\n",
    "        duplicatedvalue = data[col].duplicated().sum()\n",
    "        duplicatedrows = data.duplicated().sum()\n",
    "        missingvalue = np.sum(pd.isna(data[col]))\n",
    "        uniquevalue = data[col].nunique()\n",
    "        datatype = str(data[col].dtype)\n",
    "        \n",
    "        output.append([col, duplicatedvalue, duplicatedrows, missingvalue, uniquevalue, datatype])\n",
    "        \n",
    "    output = pd.DataFrame(output) \n",
    "    output.columns = ['Features', 'Duplicated Values', 'Duplicated Rows', 'Missing Values', 'Unique Values', 'Data Type']\n",
    "    display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc_on_bar(plot, feature):\n",
    "    total = len(feature)\n",
    "    for p in ax.patches:\n",
    "        percentage = \"{:.1f}%\".format(100 * p.get_height() / total)\n",
    "        x = p.get_x() + p.get_width() / 2 - 0.05\n",
    "        y = p.get_y() + p.get_height()\n",
    "        ax.annotate(percentage, (x, y), size=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz(data, indice):\n",
    "    fig = go.Figure(data=[go.Candlestick(x=data['UTC_Time'],\n",
    "                open=data['Open'],\n",
    "                high=data['High'],\n",
    "                low=data['Low'],\n",
    "                close=data['Close'])])\n",
    "\n",
    "    fig.update_layout(xaxis_rangeslider_visible=False,\n",
    "                      title=\"Neighbor: \" + indice + \" \" + pair + \" \" + timeframe + \" \" + now.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                      title_font_color=\"blue\",\n",
    "                      title_font_size = 20)\n",
    "    \n",
    "    fig.update_xaxes(rangebreaks=[dict(bounds=[\"sat\", \"mon\"])])\n",
    "    \n",
    "    fig.write_image(path + \"/\" + indice + \"_chart.png\")\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def market_order(instrument, units, take_profit, stop_loss):\n",
    "    login_request_body = {\n",
    "        \"order\": {\n",
    "            \"type\": \"MARKET\",\n",
    "            \"instrument\": instrument,\n",
    "            \"units\": units,\n",
    "            \"timeInForce\": \"IOC\",\n",
    "            \"positionFill\": \"DEFAULT\",\n",
    "            \"takeProfitOnFill\": {\n",
    "                \"price\": take_profit\n",
    "            },\n",
    "            \"stopLossOnFill\": {\n",
    "                \"price\": stop_loss\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(provider_api_url, data=json.dumps(login_request_body),\n",
    "                             headers=request_headers,\n",
    "                             verify=False)\n",
    "    response\n",
    "    response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Configs for Run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('config.yml') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "    oanda_api_key = cfg['creds']['oanda_api']\n",
    "    account_number = cfg['creds']['account_number'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Currency Pair</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load_10K_Records=True\n",
    "\n",
    "\n",
    "asia = ['EUR_NZD','EUR_AUD','GBP_NZD','GBP_AUD','AUD_USD','AUD_CAD','AUD_CHF','AUD_NZD','NZD_USD','NZD_CHF','NZD_CAD']\n",
    "\n",
    "currency_pairs = ['EUR_USD','EUR_GBP','EUR_NZD','EUR_AUD','EUR_CHF','EUR_CAD',\n",
    "                  'GBP_USD','GBP_CHF','GBP_NZD','GBP_AUD','GBP_CAD','AUD_USD',\n",
    "                  'AUD_CAD','AUD_CHF','AUD_NZD','NZD_USD','NZD_CHF','NZD_CAD',\n",
    "                  'USD_CAD','USD_CHF','CAD_CHF']\n",
    "\n",
    "currency_pairs = [\"EUR_USD\"]\n",
    "\n",
    "\n",
    "timeframe = \"H4\"\n",
    "#D #H1 #H4 M30\n",
    "# https://developer.oanda.com/rest-live-v20/instrument-df/#CandlestickGranularity\n",
    "price_char = \"M\"\n",
    "#M(midpoint candles) #B(bid candles) #A(ask candles) #BA\n",
    "price_com = \"mid\"\n",
    "#mid #bid #ask\n",
    "\n",
    "# def of OANDA request variable\n",
    "provider_api_url = 'https://api-fxpractice.oanda.com/v3/accounts/{}/orders'.format(account_number)\n",
    "request_headers = {\n",
    "    \"Authorization\": oanda_api_key,\n",
    "    \"Accept-Datetime-Format\": \"RFC3339\",\n",
    "    \"Connection\": \"Keep-Alive\",\n",
    "    \"Content-Type\": \"application/json;charset=UTF-8\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_authorization = 'Bearer {0}'.format(oanda_api_key)\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': provider_authorization,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "for pair in currency_pairs:\n",
    "    Log_Folder = now.strftime(\"%d-%m-%Y_%I-%M_%p\")\n",
    "    path = os.path.join(Log_Folder+\"_\"+pair)\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Candlesticks Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pricing & Spread Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in currency_pairs:\n",
    "    pricing_params = (\n",
    "        ('instruments', pair),\n",
    "    )\n",
    "    response = requests.get('https://api-fxpractice.oanda.com/v3/accounts/{}/pricing'.format(account_number),\n",
    "                            headers=headers,\n",
    "                            params=pricing_params).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = response['time']\n",
    "ask = response['prices'][0]['closeoutAsk']\n",
    "bid = response['prices'][0]['closeoutBid']\n",
    "print ('Date:', time, 'Ask:', ask, 'Bid:', bid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://api-fxpractice.oanda.com/v3/accounts/{}/openPositions'.format(account_number),\n",
    "                            headers=headers,\n",
    "                            params=pricing_params).json()\n",
    "response['positions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Candlestick Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_count = (\n",
    "    ('price', price_char),\n",
    "    ('count', '5000'),\n",
    "    ('granularity', timeframe),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for pair in currency_pairs:\n",
    "    first_response = requests.get('https://api-fxpractice.oanda.com/v3/instruments/{}/candles'.format(pair), \n",
    "                            headers=headers,\n",
    "                            params=params_count).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Load_10K_Records:\n",
    "    datetime_object = parser.parse(first_response['candles'][0]['time'])\n",
    "    date= datetime_object - relativedelta(years=3)  \n",
    "    from_date = date.replace(tzinfo=timezone.utc).timestamp()\n",
    "    params_date = (\n",
    "        ('count', '5000'),\n",
    "        ('price', price_char),\n",
    "        ('from', from_date),\n",
    "        ('granularity', timeframe),)\n",
    "\n",
    "    second_response = requests.get('https://api-fxpractice.oanda.com/v3/instruments/{}/candles'.format(pair),\n",
    "                                   headers=headers,\n",
    "                                   params=params_date).json()\n",
    "            \n",
    "    first_response= first_response['candles']  \n",
    "    second_response= second_response['candles']\n",
    "    second_response.extend(first_response)\n",
    "    response=second_response\n",
    "else:\n",
    "    response=first_response['candles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"{}_{}.csv\".format(pair, timeframe)\n",
    "output = []\n",
    "all_candlesticks = response\n",
    "\n",
    "for i in range (len(all_candlesticks)):\n",
    "    result= (convert_date(response[i]['time']))\n",
    "    output.append([(result[0]),(result[1]),(result[2]),(result[3]),(result[4]),(result[5]),\n",
    "                    response[i]['time'],\n",
    "                    response[i]['volume'], \n",
    "                    response[i][price_com]['o'],\n",
    "                    response[i][price_com]['h'],\n",
    "                    response[i][price_com]['l'],\n",
    "                    response[i][price_com]['c']])\n",
    "    \n",
    "output = pd.DataFrame(output)\n",
    "output.columns = ['Date','Time','f_time','julian_date','Weekday','Weekday_Name','UTC_Time', 'Volume', 'Open', 'High', 'Low', 'Close']\n",
    "data = output.to_csv(filename, header = True, index = False)\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()\n",
    "data = data.to_csv(filename, header = True, index = False)\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Moving Average (SMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SMA_5'] = data['Close'].rolling(window=5).mean().round(4)\n",
    "data['SMA_10'] = data['Close'].rolling(window=10).mean().round(4)\n",
    "data['SMA_20'] = data['Close'].rolling(window=20).mean().round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Moving Average Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['F_SMA_5'] = data['Close'] - data['SMA_5']\n",
    "data['F_SMA_10'] = data['Close'] - data['SMA_10']\n",
    "data['F_SMA_20'] = data['Close'] - data['SMA_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()\n",
    "data = data.to_csv(filename, header = True, index = False)\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['O-H'] = data['Open'] - data['High']\n",
    "data['O-L'] = data['Open'] - data['Low']\n",
    "data['O-C'] = data['Open'] - data['Close']\n",
    "data['H-L'] = data['High'] - data['Low']\n",
    "data['H-C'] = data['High'] - data['Close']\n",
    "data['L-C'] = data['Low'] - data['Close']\n",
    "\n",
    "data['Direction'] = data['O-C'].apply(lambda x: 1 if x<0 else 0)\n",
    "\n",
    "data['col_1'] = data['Open'] - data['Close']\n",
    "\n",
    "for value in data['col_1']:   \n",
    "    if value > 0:\n",
    "        data['col_2'] = data['High'] - data['Open']\n",
    "        data['col_3'] = data['Close'] - data['Low']\n",
    "    else:\n",
    "        data['col_2'] = data['High'] - data['Close']\n",
    "        data['col_3'] = data['Open'] - data['Low']\n",
    "\n",
    "#Two Previous Candlesticks \n",
    "data['col_4'] = data['col_1'].shift(1)\n",
    "data['col_5'] = data['col_1'].shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data = data.to_csv(filename, header = True, index = False)\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative Strength Index (RSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = data['Close'].diff()\n",
    "up = delta.clip(lower=0)\n",
    "down = -1*delta.clip(upper=0)\n",
    "ema_up = up.ewm(com=13, adjust=False).mean()\n",
    "ema_down = down.ewm(com=13, adjust=False).mean()\n",
    "rs = ema_up/ema_down\n",
    "data['RSI'] = 100 - (100/(1 + rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Average True Range (ATR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_low = data['High'] - data['Low']\n",
    "high_cp = np.abs(data['High'] - data['Close'].shift())\n",
    "low_cp = np.abs(data['Low'] - data['Close'].shift())\n",
    "df = pd.concat([high_low, high_cp, low_cp], axis=1)\n",
    "true_range = np.max(df, axis=1)\n",
    "data['ATR_14'] = true_range.rolling(14).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>CANDLE INDEX NUMBER</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candle_no = len(data) - 2\n",
    "candle_no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Loss & TakeProfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ATR = data.iloc[candle_no]['ATR_14']\n",
    "CLOSED_PRICE = data.iloc[candle_no]['Close']\n",
    "BUY_SL = (CLOSED_PRICE - ATR).round(5)\n",
    "SELL_SL = (CLOSED_PRICE + ATR).round(5)\n",
    "BUY_TP = (CLOSED_PRICE + ATR).round(5)\n",
    "SELL_TP = (CLOSED_PRICE - ATR).round(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection and Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['col_1','col_2','col_3','F_SMA_5','F_SMA_10']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Being Fit to the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling using Standard Scaler"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_col = data.iloc[:,0:].columns.tolist()\n",
    "scaler=StandardScaler()\n",
    "subset=data[all_col].copy()\n",
    "subset_scaled=scaler.fit_transform(subset)   \n",
    "subset_scaled_df=pd.DataFrame(subset_scaled,columns=subset.columns)\n",
    "subset_scaled_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clusters=range(1,10)\n",
    "meanDistortions=[]\n",
    "\n",
    "for k in clusters:\n",
    "    model=KMeans(n_clusters=k)\n",
    "    model.fit(subset_scaled_df)\n",
    "    prediction=model.predict(subset_scaled_df)\n",
    "    distortion=sum(np.min(cdist(subset_scaled_df, model.cluster_centers_, 'euclidean'), axis=1)) / subset_scaled_df.shape[0]\n",
    "                           \n",
    "    meanDistortions.append(distortion)\n",
    "\n",
    "    print('Number of Clusters:', k, '\\tAverage Distortion:', distortion)\n",
    "\n",
    "plt.plot(clusters, meanDistortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Average Distortion')\n",
    "plt.title('Selecting k with the Elbow Method', fontsize=20)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "visualizer =  KElbowVisualizer(KMeans(random_state = 1))\n",
    "visualizer.fit(subset_scaled_df)    \n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_similar_candles(candle_id, dataset, k=4):\n",
    "    indices=[]\n",
    "    distances = []\n",
    "    output = []\n",
    "    model_knn = NearestNeighbors(metric = 'euclidean', algorithm = 'auto') \n",
    "    model_knn.fit(dataset)\n",
    "    \n",
    "    #metric = 'euclidean' or 'cosine' or 'manhattan' or 'mahalanobis'\n",
    "    \n",
    "    distances, indices = model_knn.kneighbors(dataset.iloc[candle_id,:].values.reshape(1,-1),\n",
    "                                              n_neighbors = k)\n",
    "\n",
    "    for i in range(0,len(distances.flatten())):\n",
    "        if i==0:\n",
    "            display (pd.DataFrame(data.iloc[candle_id]).transpose())\n",
    "            #print(\"Recommendation for {0}:\\n\".format(eurusd_data.index[candle_id]))\n",
    "        else:\n",
    "            #print(\"{0}: {1}, with distance of {2}\".format(i,\n",
    "            #                                               dataset.index[indices.flatten()[i]],\n",
    "            #                                               distances.flatten()[i]))\n",
    "            \n",
    "            output.append ([dataset.index[indices.flatten()[i]],\n",
    "                            distances.flatten()[i],\n",
    "#                           dataset.iloc[indices.flatten()[i]]['O-H'],dataset.iloc[indices.flatten()[i]]['O-L'],dataset.iloc[indices.flatten()[i]]['O-C'],dataset.iloc[indices.flatten()[i]]['H-L'],dataset.iloc[indices.flatten()[i]]['H-C'],dataset.iloc[indices.flatten()[i]]['L-C'],\n",
    "                           dataset.iloc[indices.flatten()[i]]['col_1'],dataset.iloc[indices.flatten()[i]]['col_2'],dataset.iloc[indices.flatten()[i]]['col_3'],\n",
    "#                           dataset.iloc[indices.flatten()[i]]['col_4'],dataset.iloc[indices.flatten()[i]]['col_5'],\n",
    "                           dataset.iloc[indices.flatten()[i]]['F_SMA_5'],\n",
    "                           dataset.iloc[indices.flatten()[i]]['F_SMA_10'],\n",
    "#                           dataset.iloc[indices.flatten()[i]]['F_SMA_20'],\n",
    "#                           dataset.iloc[indices.flatten()[i]]['RSI'],\n",
    "                           ])\n",
    "    \n",
    "    output = pd.DataFrame(output)\n",
    "    output.columns = ['Indice','Distance',\n",
    "#                      'O-H','O-L','O-C','H-L','H-C','L-C',\n",
    "                      'col_1','col_2','col_3',\n",
    "#                      'col_4','col_5',\n",
    "                      'F_SMA_5',\n",
    "                      'F_SMA_10',\n",
    "#                      'F_SMA_20',\n",
    "#                      'RSI'\n",
    "                     ]\n",
    "    display (output)\n",
    "    \n",
    "    return indices, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 Similar Candlesticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, distances = find_k_similar_candles (candle_no,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = indices[0:1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Currnet Market/Candlestick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "closed_candle = \"currnet_market_data.csv\"\n",
    "data = pd.read_csv(filename)\n",
    "data = data.iloc[candle_no-30:candle_no+1]\n",
    "data.to_csv(path + \"/\" + closed_candle, header = True, index = False)\n",
    "viz(data, \"current_market\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for indice in indices[1:10]:\n",
    "    recommendation_log = \"{}_data.csv\".format(indice)\n",
    "    data = pd.read_csv(filename) \n",
    "    data = data.iloc[indice:indice+5]\n",
    "    data.to_csv(path + \"/\" + recommendation_log, header = True, index = False)\n",
    "    \n",
    "    print ('Neighbor:', indice, '|', '10K Records:', Load_10K_Records)\n",
    "    viz(data, indice.astype(str))\n",
    "    \n",
    "    data['local_max'] = data['Close'][\n",
    "        (data['Close'].shift(1) < data['Close']) & \n",
    "        (data['Close'].shift(-1) < data['Close'])]\n",
    "    data['local_min'] = data['Close'][\n",
    "        (data['Close'].shift(1) > data['Close']) &\n",
    "        (data['Close'].shift(-1) > data['Close'])]\n",
    "    \n",
    "    max_idx = argrelextrema(data['Close'].values, np.greater, order=5)[0]\n",
    "    min_idx = argrelextrema(data['Close'].values, np.less, order=5)[0]\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(data['Close'], zorder=0)\n",
    "    plt.scatter(data.iloc[max_idx].index, data.iloc[max_idx]['Close'], label='Maxima', s=100, color=\"green\", marker='^')\n",
    "    plt.scatter(data.iloc[min_idx].index, data.iloc[min_idx]['Close'], label='Minima', s=100, color=\"red\", marker='v')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    data['candleno'] = range (1, len(data) + 1)\n",
    "    X = data['candleno'].values.reshape(-1, 1)\n",
    "    Y = data['Close'].values.reshape(-1, 1)\n",
    "    linear_regressor = LinearRegression()\n",
    "    linear_regressor.fit(X, Y)\n",
    "    y_pred = linear_regressor.predict(X)\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.scatter(X, Y)\n",
    "    plt.plot(X, y_pred, color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    print(r2_score(Y, y_pred).round(2)*100, '% Fit')\n",
    "    coeficient = (linear_regressor.coef_)\n",
    "    \n",
    "    if coeficient > 0:\n",
    "        print('Action: BUY')\n",
    "        print('STOP LOSS:', BUY_SL, 'TAKE PROFIT:', BUY_TP)\n",
    "    else:\n",
    "        print('Action: SELL')\n",
    "        print('STOP LOSS:', SELL_SL, 'TAKE PROFIT:', SELL_TP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentpath = os.path.join(sys.path[0])\n",
    "pngfiles = []\n",
    "pngfiles = glob.glob(currentpath+\"/\"+path+\"/*.png\")\n",
    "pdf = FPDF()\n",
    "\n",
    "for pngfile in pngfiles:\n",
    "    pdf.add_page()\n",
    "    pdf.image(pngfile, w=200, h=130)\n",
    "    \n",
    "pdf.output(path+\"/recommendations.pdf\", \"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
