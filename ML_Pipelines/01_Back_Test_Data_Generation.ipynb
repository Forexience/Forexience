{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Test Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import calendar\n",
    "import dateutil.parser as parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import yaml\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pytz\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('back_test_pipeline_settings.yaml') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "    k_number = cfg['knn']['k_number']\n",
    "    metric = cfg['knn']['metric']\n",
    "    algorithm = cfg['knn']['algorithm']\n",
    "    feature_1 = cfg['knn']['feature_1']\n",
    "    feature_2 = cfg['knn']['feature_2']\n",
    "    feature_3 = cfg['knn']['feature_3']\n",
    "    feature_7 = cfg['knn']['feature_7']\n",
    "    feature_8 = cfg['knn']['feature_8']\n",
    "    feature_15 = cfg['knn']['feature_15']\n",
    "    volume = cfg['feature']['volume']\n",
    "    volume_size = cfg['sample']['volume_size']\n",
    "    sample_count = cfg['sample']['count']\n",
    "    candles = cfg['recommendation']['candle_count']\n",
    "    pair = cfg['currency']['pair']\n",
    "    instrument = cfg['currency']['instrument']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('K Number:',k_number)\n",
    "print('Metric:', metric)\n",
    "print('Algorithm:', algorithm)\n",
    "print('Candle Volume Size:', volume_size)\n",
    "print('Random Sample Count:', sample_count)\n",
    "print('Future Candle Count:', candles)\n",
    "print('Pair:', pair)\n",
    "print('Instrument:', instrument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(utc_time): \n",
    "    parsed_date = parser.parse(utc_time)\n",
    "    var_date=parsed_date.date()\n",
    "    var_time=parsed_date.time()\n",
    "    var_f_time=var_time.hour\n",
    "    var_julian_date=parsed_date.timetuple().tm_yday\n",
    "    var_weekday=parsed_date.weekday()\n",
    "    var_weekday_name=calendar.day_name[parsed_date.weekday()]\n",
    "    return var_date, var_time, var_f_time, var_julian_date, var_weekday, var_weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_similar_candles(candle_id, dataset, k = k_number):\n",
    "    indices=[]\n",
    "    distances = []\n",
    "    output = []\n",
    "    model_knn = NearestNeighbors(metric = metric, algorithm = algorithm) \n",
    "    model_knn.fit(dataset)\n",
    "    \n",
    "    #metric = 'euclidean' or 'cosine' or 'manhattan' or 'mahalanobis'\n",
    "    \n",
    "    distances, indices = model_knn.kneighbors(dataset.iloc[candle_id,:].values.reshape(1,-1),\n",
    "                                              n_neighbors = k)\n",
    "\n",
    "    for i in range(0,len(distances.flatten())):\n",
    "        if i!=0:\n",
    "            \n",
    "            output.append ([dataset.index[indices.flatten()[i]],\n",
    "                            distances.flatten()[i],\n",
    "                            dataset.iloc[indices.flatten()[i]][feature_1],\n",
    "                            dataset.iloc[indices.flatten()[i]][feature_2],\n",
    "                            dataset.iloc[indices.flatten()[i]][feature_3],\n",
    "                            dataset.iloc[indices.flatten()[i]][feature_7],\n",
    "                            dataset.iloc[indices.flatten()[i]][feature_8],                            \n",
    "                           ])\n",
    "    \n",
    "    output = pd.DataFrame(output)\n",
    "    output.columns = ['Indice','Distance',\n",
    "                      feature_1,\n",
    "                      feature_2,\n",
    "                      feature_3,\n",
    "                      feature_7,\n",
    "                      feature_8,\n",
    "                     ]\n",
    "   # display (output)\n",
    "    \n",
    "    return indices, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Test Configs</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '{}_H4.csv'.format(instrument)\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_med = data['Volume'].median()\n",
    "volume_med"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting n random candles where their volume is more than 5500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Candle Volume Size:', volume_size)\n",
    "print('Random Sample Count:', sample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples = data[data[volume] > volume_size].sample(n = sample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random_Candles = np.random.randint(low=1, high=len(data)-40, size=1000)\n",
    "Random_Candles = list(random_samples.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the fisrt 10 random generated candle numbers\n",
    "Random_Candles[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>CANDLE LOOP</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CST = pytz.timezone('America/Chicago')\n",
    "datetime_cst = datetime.now(CST)\n",
    "print(\"Date & Time in CST : \", \n",
    "      datetime_cst.strftime('%Y:%m:%d %H:%M:%S %Z %z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result_output = pd.DataFrame({'Candle_No':[],\n",
    "                              'Current_Market_Fit':[],\n",
    "                              'Current_Market':[],\n",
    "                              \n",
    "                              'Rec1_Close_Score':[],\n",
    "                              'Rec1_High_Score':[],\n",
    "                              'Rec1_Low_Score':[],\n",
    "                              'Rec1_HH':[],\n",
    "                              'Rec1_LL':[],\n",
    "                              \n",
    "                              'Rec2_Close_Score':[],\n",
    "                              'Rec2_High_Score':[],\n",
    "                              'Rec2_Low_Score':[],\n",
    "                              'Rec2_HH':[],\n",
    "                              'Rec2_LL':[],\n",
    "                              \n",
    "                              'Rec3_Close_Score':[],\n",
    "                              'Rec3_High_Score':[],\n",
    "                              'Rec3_Low_Score':[],\n",
    "                              'Rec3_HH':[],\n",
    "                              'Rec3_LL':[],\n",
    "                              \n",
    "                              'Rec4_Close_Score':[],\n",
    "                              'Rec4_High_Score':[],\n",
    "                              'Rec4_Low_Score':[],\n",
    "                              'Rec4_HH':[],\n",
    "                              'Rec4_LL':[],\n",
    "                             })\n",
    "\n",
    "for candle_no in Random_Candles:\n",
    "    data = pd.read_csv(filename)\n",
    "    data = data.iloc[candle_no:candle_no+candles]\n",
    "    data['candleno'] = range (1, len(data) + 1)\n",
    "    X = data['candleno'].values.reshape(-1, 1)\n",
    "    Y = data['Close'].values.reshape(-1, 1)\n",
    "    linear_regressor = LinearRegression()\n",
    "    linear_regressor.fit(X, Y)\n",
    "    y_pred = linear_regressor.predict(X) \n",
    "    \n",
    "    Current_Market_Fit = r2_score(Y, y_pred)*100\n",
    "    #print(Current_Market_Fit)\n",
    "    coeficient = (linear_regressor.coef_)\n",
    "\n",
    "    if coeficient > 0:\n",
    "        Current_Market = 1  ## Bullish / Buy ##\n",
    "    else:\n",
    "        Current_Market = 0  ## Bearish / Sell ##\n",
    "    \n",
    "    data = pd.read_csv(filename)\n",
    "    data = data[[feature_1,\n",
    "                 feature_2,\n",
    "                 feature_3,\n",
    "                 feature_7,\n",
    "                 feature_8,\n",
    "                ]]\n",
    "\n",
    "    indices, distances = find_k_similar_candles (candle_no,data)\n",
    "    indices = indices[0:1][0]\n",
    "    \n",
    "    L_L = []\n",
    "    H_H = []\n",
    "    predicted_output_1 = []\n",
    "    predicted_output_2 = []\n",
    "    predicted_output_3 = []\n",
    "\n",
    "    for indice in indices[1:5]:\n",
    "        #print (indice)\n",
    "        \n",
    "        data = pd.read_csv(filename) \n",
    "        data = data.iloc[indice:indice+candles]\n",
    "        \n",
    "        HH = data.iloc[0]['Close'] - data['High'].max()\n",
    "        LL = data.iloc[0]['Close'] - data['Low'].min()\n",
    "        \n",
    "        L_L.append([LL])\n",
    "        H_H.append([HH])\n",
    "\n",
    "        #print (HH.round(4), LL.round(4))\n",
    "\n",
    "        data['candleno'] = range (1, len(data) + 1)\n",
    "        X = data['candleno'].values.reshape(-1, 1)\n",
    "        \n",
    "        Y_Close = data['Close'].values.reshape(-1, 1)\n",
    "        linear_regressor = LinearRegression()\n",
    "        linear_regressor.fit(X, Y_Close)\n",
    "        y_pred = linear_regressor.predict(X)\n",
    "        Predicted_Market_Fit_Close = r2_score(Y_Close, y_pred)*100\n",
    "        coeficient_close = (linear_regressor.coef_)\n",
    "        if coeficient_close > 0:\n",
    "            Predicted_Trade_Close = 1    ## Buy ##\n",
    "        else:\n",
    "            Predicted_Trade_Close = -1   ## Sell ##\n",
    "        \n",
    "        predicted_output_1.append([Predicted_Market_Fit_Close * Predicted_Trade_Close])\n",
    "        #print ('****Close****', Predicted_Market_Fit_Close * Predicted_Trade_Close)\n",
    "        \n",
    "        \n",
    "        Y_High = data['High'].values.reshape(-1, 1)\n",
    "        linear_regressor.fit(X, Y_High)\n",
    "        y_pred = linear_regressor.predict(X)\n",
    "        Predicted_Market_Fit_High= r2_score(Y_High, y_pred)*100\n",
    "        coeficient_high = (linear_regressor.coef_)\n",
    "        \n",
    "        if coeficient_high > 0:\n",
    "            Predicted_Trade_High = 1    ## Buy ##\n",
    "        else:\n",
    "            Predicted_Trade_High = -1   ## Sell ##            \n",
    "        \n",
    "        predicted_output_2.append([Predicted_Market_Fit_High * Predicted_Trade_High])\n",
    "        #print ('****High****', Predicted_Market_Fit_High * Predicted_Trade_High)\n",
    "        \n",
    "        \n",
    "        Y_Low = data['Low'].values.reshape(-1, 1)\n",
    "        linear_regressor.fit(X, Y_Low)\n",
    "        y_pred = linear_regressor.predict(X)\n",
    "        Predicted_Market_Fit_Low= r2_score(Y_Low, y_pred)*100\n",
    "        coeficient_low = (linear_regressor.coef_)\n",
    "        if coeficient_low > 0:\n",
    "            Predicted_Trade_Low = 1    ## Buy ##\n",
    "        else:\n",
    "            Predicted_Trade_Low = -1   ## Sell ##\n",
    "        \n",
    "        predicted_output_3.append([Predicted_Market_Fit_Low * Predicted_Trade_Low])\n",
    "        #print ('****Low****', Predicted_Market_Fit_Low * Predicted_Trade_Low)\n",
    "        \n",
    "    \n",
    "    result = {'Candle_No': candle_no,\n",
    "              'Current_Market_Fit': Current_Market_Fit,\n",
    "              'Current_Market': Current_Market,\n",
    "              \n",
    "              'Rec1_Close_Score': predicted_output_1[0][0],\n",
    "              'Rec1_High_Score': predicted_output_2[0][0],\n",
    "              'Rec1_Low_Score': predicted_output_3[0][0],\n",
    "              'Rec1_HH': H_H[0][0],\n",
    "              'Rec1_LL': L_L[0][0],\n",
    "              \n",
    "              'Rec2_Close_Score': predicted_output_1[1][0],\n",
    "              'Rec2_High_Score': predicted_output_2[1][0],\n",
    "              'Rec2_Low_Score': predicted_output_3[1][0],\n",
    "              'Rec2_HH': H_H[1][0],\n",
    "              'Rec2_LL': L_L[1][0],\n",
    "              \n",
    "              'Rec3_Close_Score': predicted_output_1[2][0],\n",
    "              'Rec3_High_Score': predicted_output_2[2][0],\n",
    "              'Rec3_Low_Score': predicted_output_3[2][0],\n",
    "              'Rec3_HH': H_H[2][0],\n",
    "              'Rec3_LL': L_L[2][0],\n",
    "              \n",
    "              'Rec4_Close_Score': predicted_output_1[3][0],\n",
    "              'Rec4_High_Score': predicted_output_2[3][0],\n",
    "              'Rec4_Low_Score': predicted_output_3[3][0],\n",
    "              'Rec4_HH': H_H[3][0],\n",
    "              'Rec4_LL': L_L[3][0],\n",
    "             }\n",
    "    \n",
    "    result_output = result_output.append(result, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "today = now.strftime(\"%d-%m-%Y_%I-%M_%p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_output.to_csv('01_Back_Test_Data.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_output.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Log File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(today + \"_\" + \"data_generation_log_\" + pair + '.txt', \"w\")\n",
    "file.write (\"Date: \" + today + \"\\n\" + \\\n",
    "            \"Currency Pair: \" + pair + \"\\n\" + \\\n",
    "            \"K_Number: \" + str(k_number) + \"\\n\" + \\\n",
    "            \"KNN_Metric: \" + metric + \"\\n\" + \\\n",
    "            \"KNN_Algorithm: \" + algorithm + \"\\n\" + \\\n",
    "            \"Feature: \" + feature_1 + \"\\n\" + \\\n",
    "            \"Feature: \" + feature_2 + \"\\n\" + \\\n",
    "            \"Feature: \" + feature_3 + \"\\n\" + \\\n",
    "            \"Feature: \" + feature_7 + \"\\n\" + \\\n",
    "            \"Feature: \" + feature_8 + \"\\n\" + \\\n",
    "            \"Volume Size: \" + str(volume_size) + \"\\n\" + \\\n",
    "            \"Sample Count: \" + str(sample_count) + \"\\n\" + \\\n",
    "            \"Candle Counts: \" + str(candles) + \"\\n\"\n",
    "           )\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('01_Back_Test_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
