{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import calendar\n",
    "import dateutil.parser as parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import yaml\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.filterwarnings('ignore')\n",
    "from pycaret.datasets import get_data\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Candlestick Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('back_test_pipeline_settings.yaml') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "    k_number = cfg['knn']['k_number']\n",
    "    metric = cfg['knn']['metric']\n",
    "    algorithm = cfg['knn']['algorithm']\n",
    "    feature_1 = cfg['knn']['feature_1']\n",
    "    feature_2 = cfg['knn']['feature_2']\n",
    "    feature_3 = cfg['knn']['feature_3']\n",
    "    feature_7 = cfg['knn']['feature_7']\n",
    "    feature_8 = cfg['knn']['feature_8']\n",
    "    feature_9 = cfg['knn']['feature_9']\n",
    "    feature_10 = cfg['knn']['feature_10']\n",
    "    feature_11 = cfg['knn']['feature_11']\n",
    "    feature_12 = cfg['knn']['feature_12']\n",
    "    feature_13 = cfg['knn']['feature_13']\n",
    "    feature_14 = cfg['knn']['feature_14']\n",
    "    volume = cfg['feature']['volume']\n",
    "    volume_size = cfg['sample']['volume_size']\n",
    "    sample_count = cfg['sample']['count']\n",
    "    candles = cfg['recommendation']['candle_count']\n",
    "    pair = cfg['currency']['pair']\n",
    "    instrument = cfg['currency']['instrument']\n",
    "    frac = cfg['model']['frac']\n",
    "    random_state = cfg['model']['random_state']\n",
    "    model = cfg['model']['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Number: 5\n",
      "Metric: euclidean\n",
      "Algorithm: brute\n",
      "Candle Volume Size: 4000\n",
      "Random Sample Count: 10000\n",
      "Future Candle Count: 7\n",
      "Pair: EURUSD\n"
     ]
    }
   ],
   "source": [
    "print('K Number:',k_number)\n",
    "print('Metric:', metric)\n",
    "print('Algorithm:', algorithm)\n",
    "print('Candle Volume Size:', volume_size)\n",
    "print('Random Sample Count:', sample_count)\n",
    "print('Future Candle Count:', candles)\n",
    "print('Pair:', pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('config.yml') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "    oanda_api_key = cfg['creds']['oanda_api']\n",
    "    account_number = cfg['creds']['account_number'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(utc_time): \n",
    "    parsed_date = parser.parse(utc_time)\n",
    "    var_date=parsed_date.date()\n",
    "    var_time=parsed_date.time()\n",
    "    var_f_time=var_time.hour\n",
    "    var_julian_date=parsed_date.timetuple().tm_yday\n",
    "    var_weekday=parsed_date.weekday()\n",
    "    var_weekday_name=calendar.day_name[parsed_date.weekday()]\n",
    "    return var_date, var_time, var_f_time, var_julian_date, var_weekday, var_weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instrument: EUR_USD\n"
     ]
    }
   ],
   "source": [
    "print('Instrument:', instrument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load_10K_Records=True\n",
    "Load_20K_Records=True\n",
    "\n",
    "currency_pairs = [instrument]\n",
    "\n",
    "\n",
    "timeframe = \"H4\"\n",
    "#D #H1 #H4 M30\n",
    "# https://developer.oanda.com/rest-live-v20/instrument-df/#CandlestickGranularity\n",
    "price_char = \"M\"\n",
    "#M(midpoint candles) #B(bid candles) #A(ask candles) #BA\n",
    "price_com = \"mid\"\n",
    "#mid #bid #ask\n",
    "\n",
    "# def of OANDA request variable\n",
    "provider_api_url = 'https://api-fxpractice.oanda.com/v3/accounts/{}/orders'.format(account_number)\n",
    "request_headers = {\n",
    "    \"Authorization\": oanda_api_key,\n",
    "    \"Accept-Datetime-Format\": \"RFC3339\",\n",
    "    \"Connection\": \"Keep-Alive\",\n",
    "    \"Content-Type\": \"application/json;charset=UTF-8\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_authorization = 'Bearer {0}'.format(oanda_api_key)\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': provider_authorization,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_count = (\n",
    "    ('price', price_char),\n",
    "    ('count', '5000'),\n",
    "    ('granularity', timeframe),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in currency_pairs:\n",
    "    first_response = requests.get('https://api-fxpractice.oanda.com/v3/instruments/{}/candles'.format(pair), \n",
    "                            headers=headers,\n",
    "                            params=params_count).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Load_10K_Records:\n",
    "    \n",
    "    #### Load 10K data\n",
    "        \n",
    "    datetime_object = parser.parse(first_response['candles'][0]['time'])\n",
    "    date= datetime_object - relativedelta(years=3)  \n",
    "    from_date = date.replace(tzinfo=timezone.utc).timestamp()\n",
    "    params_date = (\n",
    "        ('count', '5000'),\n",
    "        ('price', price_char),\n",
    "        ('from', from_date),\n",
    "        ('granularity', timeframe),)\n",
    "\n",
    "    second_response = requests.get('https://api-fxpractice.oanda.com/v3/instruments/{}/candles'.format(pair),\n",
    "                                   headers=headers,\n",
    "                                   params=params_date).json()\n",
    "    datetime_object_15K = parser.parse(second_response['candles'][0]['time'])\n",
    "    first_response= first_response['candles']  \n",
    "    second_response= second_response['candles']\n",
    "    second_response.extend(first_response)\n",
    "    \n",
    "    if Load_20K_Records:\n",
    "\n",
    "        #### Load 15K data\n",
    "\n",
    "        date= datetime_object_15K - relativedelta(years=3)  \n",
    "        from_date = date.replace(tzinfo=timezone.utc).timestamp()\n",
    "        params_date = (\n",
    "            ('count', '5000'),\n",
    "            ('price', price_char),\n",
    "            ('from', from_date),\n",
    "            ('granularity', timeframe),)\n",
    "\n",
    "        third_response = requests.get('https://api-fxpractice.oanda.com/v3/instruments/{}/candles'.format(pair),\n",
    "                                       headers=headers,\n",
    "                                       params=params_date).json()\n",
    "        datetime_object_20K = parser.parse(third_response['candles'][0]['time'])\n",
    "        third_response= third_response['candles']\n",
    "        third_response.extend(second_response)\n",
    "\n",
    "        #### Load 20K data\n",
    "\n",
    "        date= datetime_object_20K - relativedelta(years=3)  \n",
    "        from_date = date.replace(tzinfo=timezone.utc).timestamp()\n",
    "        params_date = (\n",
    "            ('count', '5000'),\n",
    "            ('price', price_char),\n",
    "            ('from', from_date),\n",
    "            ('granularity', timeframe),)\n",
    "\n",
    "        fourth_response = requests.get('https://api-fxpractice.oanda.com/v3/instruments/{}/candles'.format(pair),\n",
    "                                       headers=headers,\n",
    "                                       params=params_date).json()\n",
    "        datetime_object_20K = parser.parse(fourth_response['candles'][0]['time'])\n",
    "        fourth_response= fourth_response['candles']\n",
    "        fourth_response.extend(third_response)\n",
    "\n",
    "        response=fourth_response\n",
    "    else:\n",
    "       response=second_response \n",
    "else:\n",
    "    response=first_response['candles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"{}_{}.csv\".format(pair, timeframe)\n",
    "output = []\n",
    "all_candlesticks = response\n",
    "\n",
    "for i in range (len(all_candlesticks)):\n",
    "    result= (convert_date(response[i]['time']))\n",
    "    output.append([(result[0]),(result[1]),(result[2]),(result[3]),(result[4]),(result[5]),\n",
    "                    response[i]['time'],\n",
    "                    response[i]['volume'], \n",
    "                    response[i][price_com]['o'],\n",
    "                    response[i][price_com]['h'],\n",
    "                    response[i][price_com]['l'],\n",
    "                    response[i][price_com]['c']])\n",
    "    \n",
    "output = pd.DataFrame(output)\n",
    "output.columns = ['Date','Time','f_time','julian_date','Weekday','Weekday_Name','UTC_Time', 'Volume', 'Open', 'High', 'Low', 'Close']\n",
    "data = output.to_csv(filename, header = True, index = False)\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()\n",
    "data = data.to_csv(filename, header = True, index = False)\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19342, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SMA_5'] = data['Close'].rolling(window=5).mean().round(4)\n",
    "data['SMA_10'] = data['Close'].rolling(window=10).mean().round(4)\n",
    "data['SMA_20'] = data['Close'].rolling(window=20).mean().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['F_SMA_5'] = data['Close'] - data['SMA_5']\n",
    "data['F_SMA_10'] = data['Close'] - data['SMA_10']\n",
    "data['F_SMA_20'] = data['Close'] - data['SMA_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()\n",
    "data = data.to_csv(filename, header = True, index = False)\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['O-H'] = data['Open'] - data['High']\n",
    "data['O-L'] = data['Open'] - data['Low']\n",
    "data['O-C'] = data['Open'] - data['Close']\n",
    "data['H-L'] = data['High'] - data['Low']\n",
    "data['H-C'] = data['High'] - data['Close']\n",
    "data['L-C'] = data['Low'] - data['Close']\n",
    "\n",
    "data['Direction'] = data['O-C'].apply(lambda x: 1 if x<0 else 0)\n",
    "\n",
    "data['col_1'] = data['Open'] - data['Close']\n",
    "\n",
    "for value in data['col_1']:   \n",
    "    if value > 0:\n",
    "        data['col_2'] = data['High'] - data['Open']\n",
    "        data['col_3'] = data['Close'] - data['Low']\n",
    "    else:\n",
    "        data['col_2'] = data['High'] - data['Close']\n",
    "        data['col_3'] = data['Open'] - data['Low']\n",
    "\n",
    "#Two Previous Candlesticks \n",
    "data['col_4'] = data['col_1'].shift(1)\n",
    "data['col_5'] = data['col_1'].shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data = data.to_csv(filename, header = True, index = False)\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19323, 30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(utc_time): \n",
    "    parsed_date = parser.parse(utc_time)\n",
    "    var_date=parsed_date.date()\n",
    "    var_time=parsed_date.time()\n",
    "    var_f_time=var_time.hour\n",
    "    var_julian_date=parsed_date.timetuple().tm_yday\n",
    "    var_weekday=parsed_date.weekday()\n",
    "    var_weekday_name=calendar.day_name[parsed_date.weekday()]\n",
    "    return var_date, var_time, var_f_time, var_julian_date, var_weekday, var_weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Number: 5\n",
      "Metric: euclidean\n",
      "Algorithm: brute\n"
     ]
    }
   ],
   "source": [
    "print('K Number:',k_number)\n",
    "print('Metric:', metric)\n",
    "print('Algorithm:', algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_similar_candles(candle_id, dataset, k = k_number):\n",
    "    indices=[]\n",
    "    distances = []\n",
    "    output = []\n",
    "    model_knn = NearestNeighbors(metric = metric, algorithm = algorithm) \n",
    "    model_knn.fit(dataset)\n",
    "    \n",
    "    #metric = 'euclidean' or 'cosine' or 'manhattan' or 'mahalanobis'\n",
    "    \n",
    "    distances, indices = model_knn.kneighbors(dataset.iloc[candle_id,:].values.reshape(1,-1),\n",
    "                                              n_neighbors = k)\n",
    "\n",
    "    for i in range(0,len(distances.flatten())):\n",
    "        if i!=0:\n",
    "            \n",
    "            output.append ([dataset.index[indices.flatten()[i]],\n",
    "                            distances.flatten()[i],\n",
    "                            dataset.iloc[indices.flatten()[i]][feature_9],\n",
    "                            dataset.iloc[indices.flatten()[i]][feature_10],\n",
    "                            dataset.iloc[indices.flatten()[i]][feature_11],\n",
    "                            dataset.iloc[indices.flatten()[i]][feature_12],\n",
    "                            dataset.iloc[indices.flatten()[i]][feature_13],\n",
    "                            dataset.iloc[indices.flatten()[i]][feature_14],\n",
    "                           ])\n",
    "    \n",
    "    output = pd.DataFrame(output)\n",
    "    output.columns = ['Indice','Distance',\n",
    "                      feature_9,\n",
    "                      feature_10,\n",
    "                      feature_11,\n",
    "                      feature_12,\n",
    "                      feature_13,\n",
    "                      feature_14,\n",
    "                     ]\n",
    "   # display (output)\n",
    "    \n",
    "    return indices, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Test Configs</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '{}_H4.csv'.format(instrument)\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Time', 'f_time', 'julian_date', 'Weekday', 'Weekday_Name',\n",
       "       'UTC_Time', 'Volume', 'Open', 'High', 'Low', 'Close', 'SMA_5', 'SMA_10',\n",
       "       'SMA_20', 'F_SMA_5', 'F_SMA_10', 'F_SMA_20', 'O-H', 'O-L', 'O-C', 'H-L',\n",
       "       'H-C', 'L-C', 'Direction', 'col_1', 'col_2', 'col_3', 'col_4', 'col_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting n random candles where their volume is more than x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candle Volume Size: 4000\n",
      "Random Sample Count: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Candle Volume Size:', volume_size)\n",
    "print('Random Sample Count:', sample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples = data[data[volume] > volume_size].sample(n = sample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random_Candles = np.random.randint(low=1, high=len(data)-40, size=1000)\n",
    "Random_Candles = list(random_samples.index.values)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#show the fisrt 10 random generated candle numbers\n",
    "Random_Candles[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>CANDLE LOOP</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "today = now.strftime(\"%d-%m-%Y_%I-%M_%p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today: 03-02-2022_05-52_AM\n",
      "CPU times: user 5h 54min 57s, sys: 6h 54min 18s, total: 12h 49min 16s\n",
      "Wall time: 2h 19min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print ('Today: ' + today)\n",
    "\n",
    "result_output = pd.DataFrame({'Candle_No':[],\n",
    "                              'Current_Market_Fit':[],\n",
    "                              'Current_Market':[],\n",
    "                              'Rec1_Score':[],\n",
    "                              'Rec1_Prediction':[],\n",
    "                              'Rec2_Score':[],\n",
    "                              'Rec2_Prediction':[],\n",
    "                              'Rec3_Score':[],\n",
    "                              'Rec3_Prediction':[],\n",
    "                              'Rec4_Score':[],\n",
    "                              'Rec4_Prediction':[]\n",
    "                             })\n",
    "\n",
    "for candle_no in Random_Candles:\n",
    "    data = pd.read_csv(filename)\n",
    "    data = data.iloc[candle_no:candle_no+candles]\n",
    "    data['candleno'] = range (1, len(data) + 1)\n",
    "    X = data['candleno'].values.reshape(-1, 1)\n",
    "    Y = data['Close'].values.reshape(-1, 1)\n",
    "    linear_regressor = LinearRegression()\n",
    "    linear_regressor.fit(X, Y)\n",
    "    y_pred = linear_regressor.predict(X) \n",
    "    \n",
    "    Current_Market_Fit = r2_score(Y, y_pred)*100\n",
    "    #print(Current_Market_Fit)\n",
    "    coeficient = (linear_regressor.coef_)\n",
    "\n",
    "    if coeficient > 0:\n",
    "        Current_Market='Bullish'\n",
    "    else:\n",
    "        Current_Market = 'Bearish'\n",
    "    \n",
    "    data = pd.read_csv(filename)\n",
    "    data = data[[feature_9,\n",
    "                 feature_10,\n",
    "                 feature_11,\n",
    "                 feature_12,\n",
    "                 feature_13,\n",
    "                 feature_14,\n",
    "                ]]\n",
    "\n",
    "    indices, distances = find_k_similar_candles (candle_no,data)\n",
    "    indices = indices[0:1][0]\n",
    "    \n",
    "    predicted_output = []\n",
    "    recs = []\n",
    "    for indice in indices[1:5]:\n",
    "             \n",
    "        Predicted_Market_Fit =0\n",
    "        Predicted_Trade=''\n",
    "    \n",
    "        data = pd.read_csv(filename) \n",
    "        data = data.iloc[indice:indice+candles]\n",
    "\n",
    "        data['candleno'] = range (1, len(data) + 1)\n",
    "        X = data['candleno'].values.reshape(-1, 1)\n",
    "        Y = data['Close'].values.reshape(-1, 1)\n",
    "        linear_regressor = LinearRegression()\n",
    "        linear_regressor.fit(X, Y)\n",
    "        y_pred = linear_regressor.predict(X)\n",
    "\n",
    "        Predicted_Market_Fit= r2_score(Y, y_pred)*100\n",
    "        coeficient = (linear_regressor.coef_)\n",
    "\n",
    "        if coeficient > 0:\n",
    "            Predicted_Trade= 'BUY'\n",
    "        else:\n",
    "            Predicted_Trade = 'SELL'\n",
    "        \n",
    "        predicted_output.append([Predicted_Market_Fit,Predicted_Trade])\n",
    "        \n",
    "    result = {'Candle_No': candle_no,\n",
    "              'Current_Market_Fit': Current_Market_Fit,\n",
    "              'Current_Market': Current_Market,\n",
    "              'Rec1_Score': predicted_output[0][0],\n",
    "              'Rec1_Prediction': predicted_output[0][1],\n",
    "              'Rec2_Score': predicted_output[1][0],\n",
    "              'Rec2_Prediction': predicted_output[1][1],\n",
    "              'Rec3_Score': predicted_output[2][0],\n",
    "              'Rec3_Prediction': predicted_output[2][1],\n",
    "              'Rec4_Score': predicted_output[3][0],\n",
    "              'Rec4_Prediction': predicted_output[3][1],\n",
    "             }\n",
    "    \n",
    "    result_output = result_output.append(result, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candle_No</th>\n",
       "      <th>Current_Market_Fit</th>\n",
       "      <th>Current_Market</th>\n",
       "      <th>Rec1_Score</th>\n",
       "      <th>Rec1_Prediction</th>\n",
       "      <th>Rec2_Score</th>\n",
       "      <th>Rec2_Prediction</th>\n",
       "      <th>Rec3_Score</th>\n",
       "      <th>Rec3_Prediction</th>\n",
       "      <th>Rec4_Score</th>\n",
       "      <th>Rec4_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16061.0</td>\n",
       "      <td>83.429012</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>76.350292</td>\n",
       "      <td>BUY</td>\n",
       "      <td>7.589357</td>\n",
       "      <td>SELL</td>\n",
       "      <td>0.008686</td>\n",
       "      <td>SELL</td>\n",
       "      <td>81.222464</td>\n",
       "      <td>SELL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9351.0</td>\n",
       "      <td>25.720240</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>8.170866</td>\n",
       "      <td>BUY</td>\n",
       "      <td>4.948899</td>\n",
       "      <td>SELL</td>\n",
       "      <td>8.225812</td>\n",
       "      <td>BUY</td>\n",
       "      <td>91.143435</td>\n",
       "      <td>SELL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18840.0</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>25.144194</td>\n",
       "      <td>SELL</td>\n",
       "      <td>88.790150</td>\n",
       "      <td>SELL</td>\n",
       "      <td>38.352318</td>\n",
       "      <td>SELL</td>\n",
       "      <td>13.709951</td>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2467.0</td>\n",
       "      <td>48.130979</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>39.009064</td>\n",
       "      <td>SELL</td>\n",
       "      <td>80.836492</td>\n",
       "      <td>SELL</td>\n",
       "      <td>73.367726</td>\n",
       "      <td>SELL</td>\n",
       "      <td>82.929540</td>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2877.0</td>\n",
       "      <td>61.181974</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>1.430894</td>\n",
       "      <td>BUY</td>\n",
       "      <td>25.141188</td>\n",
       "      <td>BUY</td>\n",
       "      <td>74.599068</td>\n",
       "      <td>BUY</td>\n",
       "      <td>1.287533</td>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Candle_No  Current_Market_Fit Current_Market  Rec1_Score Rec1_Prediction  \\\n",
       "0    16061.0           83.429012        Bearish   76.350292             BUY   \n",
       "1     9351.0           25.720240        Bullish    8.170866             BUY   \n",
       "2    18840.0            0.009115        Bearish   25.144194            SELL   \n",
       "3     2467.0           48.130979        Bullish   39.009064            SELL   \n",
       "4     2877.0           61.181974        Bearish    1.430894             BUY   \n",
       "\n",
       "   Rec2_Score Rec2_Prediction  Rec3_Score Rec3_Prediction  Rec4_Score  \\\n",
       "0    7.589357            SELL    0.008686            SELL   81.222464   \n",
       "1    4.948899            SELL    8.225812             BUY   91.143435   \n",
       "2   88.790150            SELL   38.352318            SELL   13.709951   \n",
       "3   80.836492            SELL   73.367726            SELL   82.929540   \n",
       "4   25.141188             BUY   74.599068             BUY    1.287533   \n",
       "\n",
       "  Rec4_Prediction  \n",
       "0            SELL  \n",
       "1            SELL  \n",
       "2             BUY  \n",
       "3             BUY  \n",
       "4             BUY  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_output.to_csv('01_Back_Test_Data.csv', header = True, index = False)\n",
    "result_output.to_csv(today + \"_\" + \"Back_Test_Data_\" + pair + '.csv', header = True, index = False)\n",
    "result_output = pd.read_csv(today + \"_\" + \"Back_Test_Data_\" + pair + '.csv')\n",
    "result_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Log File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(today + \"_\" + \"data_generation_log_\" + pair + '.txt', \"w\")\n",
    "file.write (\"Date: \" + today + \"\\n\" + \\\n",
    "            \"Currency Pair: \" + pair + \"\\n\" + \\\n",
    "            \"K_Number: \" + str(k_number) + \"\\n\" + \\\n",
    "            \"KNN_Metric: \" + metric + \"\\n\" + \\\n",
    "            \"KNN_Algorithm: \" + algorithm + \"\\n\" + \\\n",
    "            \"Feature: \" + feature_9 + \"\\n\" + \\\n",
    "            \"Feature: \" + feature_10 + \"\\n\" + \\\n",
    "            \"Feature: \" + feature_11 + \"\\n\" + \\\n",
    "            \"Feature: \" + feature_12 + \"\\n\" + \\\n",
    "            \"Feature: \" + feature_13 + \"\\n\" + \\\n",
    "            \"Feature: \" + feature_14 + \"\\n\" + \\\n",
    "            \"Volume Size: \" + str(volume_size) + \"\\n\" + \\\n",
    "            \"Sample Count: \" + str(sample_count) + \"\\n\" + \\\n",
    "            \"Candle Counts: \" + str(candles) + \"\\n\"\n",
    "           )\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('back_test_pipeline_settings.yaml') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "    frac = cfg['model']['frac']\n",
    "    random_state = cfg['model']['random_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pair:', pair)\n",
    "print('Fraction:', frac)\n",
    "print('Random State:', random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "today = now.strftime(\"%d-%m-%Y_%I-%M_%p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('01_Back_Test_Data.csv')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['Current_Market_Fit'] > 20]\n",
    "dataset = dataset.reset_index()\n",
    "del dataset['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Current_Market'] = dataset['Current_Market'].replace(['Bullish','Bearish'],[1,0])\n",
    "dataset['Rec1_Prediction'] = dataset['Rec1_Prediction'].replace(['BUY','SELL'],[1,-1])\n",
    "dataset['Rec2_Prediction'] = dataset['Rec2_Prediction'].replace(['BUY','SELL'],[1,-1])\n",
    "dataset['Rec3_Prediction'] = dataset['Rec3_Prediction'].replace(['BUY','SELL'],[1,-1])\n",
    "dataset['Rec4_Prediction'] = dataset['Rec4_Prediction'].replace(['BUY','SELL'],[1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Rec1_Score'] = dataset['Rec1_Score'] * dataset['Rec1_Prediction']\n",
    "dataset['Rec2_Score'] = dataset['Rec2_Score'] * dataset['Rec2_Prediction']\n",
    "dataset['Rec3_Score'] = dataset['Rec3_Score'] * dataset['Rec3_Prediction']\n",
    "dataset['Rec4_Score'] = dataset['Rec4_Score'] * dataset['Rec4_Prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Rec1_Score'] = dataset['Rec1_Score'].round(2)\n",
    "dataset['Rec2_Score'] = dataset['Rec2_Score'].round(2)\n",
    "dataset['Rec3_Score'] = dataset['Rec3_Score'].round(2)\n",
    "dataset['Rec4_Score'] = dataset['Rec4_Score'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop([\n",
    "    'Candle_No',\n",
    "    'Current_Market_Fit',\n",
    "    'Rec1_Prediction',\n",
    "    'Rec2_Prediction',\n",
    "    'Rec3_Prediction',\n",
    "    'Rec4_Prediction',\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.sample(frac=frac, random_state=random_state).reset_index(drop=True)\n",
    "data_unseen = dataset.drop(data.index).reset_index(drop=True)\n",
    "\n",
    "print('Data for Modeling: ' + str(data.shape))\n",
    "print('Unseen Data For Predictions: ' + str(data_unseen.shape))\n",
    "print('Fraction: ' + str(frac))\n",
    "#print('Random State: ', str(random_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unseen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unseen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_name = setup(data = data,\n",
    "                 target = 'Current_Market',\n",
    "#                 fold_shuffle=True,\n",
    "                 session_id=123,\n",
    "                 silent=True,\n",
    "#                 n_jobs = 64,\n",
    "#                 imputation_type='iterative'\n",
    "                ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('back_test_pipeline_settings.yaml') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "    model = cfg['model']['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model Name:', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = create_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(MODEL, plot = 'confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNED_MODEL = tune_model(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(TUNED_MODEL, plot = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(TUNED_MODEL, plot = 'pr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(TUNED_MODEL, plot='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(TUNED_MODEL, plot = 'confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model(TUNED_MODEL);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_MODEL = finalize_model(TUNED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FINAL_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model(FINAL_MODEL);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_predictions = predict_model(FINAL_MODEL, data=data_unseen)\n",
    "unseen_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(FINAL_MODEL, plot = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_name = (today + \"_\" + model + \"_\" + pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(FINAL_MODEL, pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_FINAL_MODEL = load_model(pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prediction = predict_model(SAVED_FINAL_MODEL, data=data_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unseen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prediction.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(today + \"_\" + model + \"_binary_classification_log_\" + pair + \".txt\", \"w\")\n",
    "file.write (\"Date: \" + today + \"\\n\" + \\\n",
    "            \"Currency Pair: \" + pair + \"\\n\" + \\\n",
    "            \"Model: \" + model + \"\\n\" + \\\n",
    "            \"Frac: \" + str(frac) + \"\\n\" + \\\n",
    "            \"Random State: \" + str(random_state) + \"\\n\" )\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '{}_H4.csv'.format(instrument)\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples = data[data[volume] > volume_size].sample(n = sample_count)\n",
    "Test_Candle = list(random_samples.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR_FINAL_MODEL = load_model('FINAL_MODELS/EURUSD/FINAL_LR_25Nov2021_EURUSD')\n",
    "#ET_FINAL_MODEL = load_model('FINAL_MODELS/EURUSD/FINAL_ET_25Nov2021_EURUSD')\n",
    "KNN_FINAL_MODEL = load_model('02-02-2022_03-42_AM_knn_EUR_USD')\n",
    "#DT_FINAL_MODEL = load_model('FINAL_MODELS/USDCAD/10-01-2022_06-15_AM_dt_USDCAD')\n",
    "#GBC_FINAL_MODEL = load_model('FINAL_MODELS/USDCAD/10-01-2022_07-12_AM_gbc_USDCAD')\n",
    "#LIGHTGBM_FINAL_MODEL = load_model('FINAL_MODELS/GBPUSD/09-01-2022_10-58_PM_lightgbm_GBPUSD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print ('Today: ' + today)\n",
    "\n",
    "result_output = pd.DataFrame({'Candle_No':[],\n",
    "                              'Current_Market_Fit':[],\n",
    "                              'Current_Market':[],\n",
    "#                              'Rec1':[],\n",
    "#                              'Rec1_P':[],\n",
    "#                              'Rec2':[],\n",
    "#                              'Rec2_P':[],\n",
    "#                              'Rec3':[],\n",
    "#                              'Rec3_P':[],\n",
    "#                              'LR_Label':[],\n",
    "#                              'LR_Score':[],\n",
    "#                              'ET_Label':[],\n",
    "#                              'ET_Score':[],\n",
    "                              'KNN_Label':[],\n",
    "                              'KNN_Score':[],\n",
    "#                              'DT_Label':[],\n",
    "#                              'DT_Score':[],\n",
    "#                              'LIGHTGBM_Label':[],\n",
    "#                              'LIGHTGBM_Score':[],\n",
    "#                              'GBC_Label':[],\n",
    "#                              'GBC_Score':[],                              \n",
    "                             })\n",
    "\n",
    "for candle_no in Test_Candle:\n",
    "    data = pd.read_csv(filename)\n",
    "    data = data.iloc[candle_no:candle_no+candles]\n",
    "    data['candleno'] = range (1, len(data) + 1)\n",
    "    X = data['candleno'].values.reshape(-1, 1)\n",
    "    Y = data['Close'].values.reshape(-1, 1)\n",
    "    linear_regressor = LinearRegression()\n",
    "    linear_regressor.fit(X, Y)\n",
    "    y_pred = linear_regressor.predict(X) \n",
    "    \n",
    "    Current_Market_Fit = r2_score(Y, y_pred)*100\n",
    "    coeficient = (linear_regressor.coef_)\n",
    "\n",
    "    if coeficient > 0:\n",
    "        Current_Market= 1\n",
    "\n",
    "    else:\n",
    "        Current_Market = 0\n",
    "\n",
    "    data = pd.read_csv(filename)\n",
    "    data = data[[feature_9,\n",
    "                 feature_10,\n",
    "                 feature_11,\n",
    "                 feature_12,\n",
    "                 feature_13,\n",
    "                 feature_14,\n",
    "                ]]\n",
    "\n",
    "    indices, distances = find_k_similar_candles (candle_no,data)\n",
    "    indices = indices[0:1][0]\n",
    "    \n",
    "    predicted_output = []\n",
    "    recs = []\n",
    "    for indice in indices[1:5]:\n",
    "             \n",
    "        Predicted_Market_Fit =0\n",
    "        Predicted_Trade=''\n",
    "    \n",
    "        data = pd.read_csv(filename) \n",
    "        data = data.iloc[indice:indice+candles]\n",
    "\n",
    "        data['candleno'] = range (1, len(data) + 1)\n",
    "        X = data['candleno'].values.reshape(-1, 1)\n",
    "        Y = data['Close'].values.reshape(-1, 1)\n",
    "        linear_regressor = LinearRegression()\n",
    "        linear_regressor.fit(X, Y)\n",
    "        y_pred = linear_regressor.predict(X)\n",
    "\n",
    "        Predicted_Market_Fit= r2_score(Y, y_pred)*100\n",
    "        coeficient = (linear_regressor.coef_)\n",
    "\n",
    "        if coeficient > 0:\n",
    "            Predicted_Trade = 'BUY'\n",
    "            recs.append((r2_score(Y, y_pred)*100))\n",
    "        else:\n",
    "            Predicted_Trade = 'SELL'\n",
    "            recs.append((r2_score(Y, y_pred)*100) * -1)\n",
    "        \n",
    "        predicted_output.append([Predicted_Market_Fit,Predicted_Trade])\n",
    "        \n",
    "        \n",
    "    data_unseen = pd.DataFrame ({\n",
    "        'Rec1_Score': [recs[0]],\n",
    "        'Rec2_Score': [recs[1]],\n",
    "        'Rec3_Score': [recs[2]],\n",
    "        'Rec4_Score': [recs[3]],\n",
    "    })\n",
    "    \n",
    "#    lr_prediction = predict_model(LR_FINAL_MODEL, data=data_unseen)\n",
    "#    LR_Label = lr_prediction['Label']\n",
    "#    LR_Score = lr_prediction['Score']\n",
    "    \n",
    "#    et_prediction = predict_model(ET_FINAL_MODEL, data=data_unseen)\n",
    "#    ET_Label = et_prediction['Label']\n",
    "#    ET_Score = et_prediction['Score']\n",
    "    \n",
    "    knn_prediction = predict_model(KNN_FINAL_MODEL, data=data_unseen)\n",
    "    KNN_Label = knn_prediction['Label']\n",
    "    KNN_Score = knn_prediction['Score']\n",
    "    \n",
    "#    dt_prediction = predict_model(DT_FINAL_MODEL, data=data_unseen)\n",
    "#    DT_Label = dt_prediction['Label']\n",
    "#    DT_Score = dt_prediction['Score']\n",
    "    \n",
    "#    lightgbm_prediction = predict_model(LIGHTGBM_FINAL_MODEL, data=data_unseen)\n",
    "#    LIGHTGBM_Label = lightgbm_prediction['Label']\n",
    "#    LIGHTGBM_Score = lightgbm_prediction['Score']\n",
    "\n",
    "#    gbc_prediction = predict_model(GBC_FINAL_MODEL, data=data_unseen)\n",
    "#    GBC_Label = gbc_prediction['Label']\n",
    "#    GBC_Score = gbc_prediction['Score']    \n",
    "    \n",
    "    result = {'Candle_No': candle_no,\n",
    "              'Current_Market_Fit': Current_Market_Fit,\n",
    "              'Current_Market': Current_Market,\n",
    "#              'Rec1': predicted_output[0][0],\n",
    "#              'Rec1_P': predicted_output[0][1],\n",
    "#              'Rec2': predicted_output[1][0],\n",
    "#              'Rec2_P': predicted_output[1][1],\n",
    "#              'Rec3': predicted_output[2][0],\n",
    "#              'Rec3_P': predicted_output[2][1],\n",
    "#              'LR_Label': LR_Label[0],\n",
    "#              'LR_Score': LR_Score[0],\n",
    "#              'ET_Label': ET_Label[0],\n",
    "#              'ET_Score': ET_Score[0],\n",
    "              'KNN_Label': KNN_Label[0],\n",
    "              'KNN_Score': KNN_Score[0],\n",
    "#              'DT_Label': DT_Label[0],\n",
    "#              'DT_Score': DT_Score[0],\n",
    "#              'LIGHTGBM_Label': LIGHTGBM_Label[0],\n",
    "#              'LIGHTGBM_Score': LIGHTGBM_Score[0],\n",
    "#              'GBC_Label': GBC_Label[0],\n",
    "#              'GBC_Score': GBC_Score[0],              \n",
    "             }\n",
    "    \n",
    "    result_output = result_output.append(result, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_output.to_csv('03_Back_Test_Final_Result_' + today + '.csv', header = True, index = False)\n",
    "result_output = pd.read_csv('03_Back_Test_Final_Result_' + today + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_output = result_output[result_output['Current_Market_Fit'] > 20]\n",
    "result_output = result_output.reset_index()\n",
    "del result_output['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_output.to_csv('03_Back_Test_Final_Result_' + today + '.csv', header = True, index = False)\n",
    "result_output = pd.read_csv('03_Back_Test_Final_Result_' + today + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_output['LR_Prediction'] = result_output['Current_Market'] - result_output['LR_Label']\n",
    "#result_output['ET_Prediction'] = result_output['Current_Market'] - result_output['ET_Label']\n",
    "result_output['KNN_Prediction'] = result_output['Current_Market'] - result_output['KNN_Label']\n",
    "#result_output['DT_Prediction'] = result_output['Current_Market'] - result_output['DT_Label']\n",
    "#result_output['LIGHTGBM_Prediction'] = result_output['Current_Market'] - result_output['LIGHTGBM_Label']\n",
    "#result_output['GBC_Prediction'] = result_output['Current_Market'] - result_output['GBC_Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_Result = pd.DataFrame(result_output['KNN_Prediction'].value_counts())\n",
    "KNN_Result[\"Score\"] = (KNN_Result['KNN_Prediction'] * 100 / len(result_output)).round(2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GBC_Result = pd.DataFrame(result_output['GBC_Prediction'].value_counts())\n",
    "GBC_Result[\"Score\"] = (GBC_Result['GBC_Prediction'] * 100 / len(result_output)).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([\n",
    "#    LR_Result,\n",
    "#    ET_Result,\n",
    "    KNN_Result,\n",
    "#    DT_Result,\n",
    "#    GBC_Result,\n",
    "#    LIGHTGBM_Result,\n",
    "], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
